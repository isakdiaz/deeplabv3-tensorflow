{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "treeseg_coreml.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNg6BG8JFJvFOyJAW59lECT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isakdiaz/deeplabv3-tree-segmentation/blob/master/treeseg_coreml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuWqzi58oPZU"
      },
      "source": [
        "# CoreML Conversion from Tensorflow Model\n",
        "Notebook is for loading DeepLabV3 tree segmentation model from google drive and doing a CoreML conversion so you can generate an mlmodel file that runs on iOS devices. Run treeseg_train.ipynb first if you still do not have a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cnpWQoIQ3uW"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pprint\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import json\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "print(f\"Running tensorflow version {tf.__version__}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7KpDm6dQZMs"
      },
      "source": [
        "## Load Cloud Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D62UafuKB5N7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXZUk33Vpvug"
      },
      "source": [
        "## Install CoreML Tools\n",
        "(Requires Python 3.5 +)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mzwPPEopvfX"
      },
      "source": [
        "!pip install coremltools\n",
        "import coremltools as ct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRLMRzjKQe8z"
      },
      "source": [
        "# Load Model File\n",
        "Root directory of my google drive has saved_models folder which contains models. If you ran treeseg_train.ipynb\n",
        " your model folder should be in the same folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLBCWq0t1K6B"
      },
      "source": [
        "# Check if a model exists\n",
        "GDRIVE_FOLDER = \"/content/drive/MyDrive\"\n",
        "MODEL_FOLDER = \"saved_models/treeseg\"\n",
        "\n",
        "!ls -all -h {os.path.join(GDRIVE_FOLDER, MODEL_FOLDER)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfXFLnyDBGYN"
      },
      "source": [
        "# Pick a model and replace model filename parameter\n",
        "MODEL_FILENAME = \"treeseg_2021-09-02.h5\"\n",
        "\n",
        "model_filepath = os.path.join(GDRIVE_FOLDER, MODEL_FOLDER, MODEL_FILENAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5aLJeatrXcr"
      },
      "source": [
        "## Load custom loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn_Okg7GrbCh"
      },
      "source": [
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eonD8uJRrt7h"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_zQ7ynto5ZF"
      },
      "source": [
        "with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss}):\n",
        "  model = tf.keras.models.load_model(model_filepath)\n",
        "\n",
        "print(f\"Model loaded from path {model_filepath}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNJtaYh1u3v2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4GgUXrt1Xqf"
      },
      "source": [
        "# Convert Keras model to CoreML Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDg9OBaYqRMd"
      },
      "source": [
        "# image_input = ct.ImageType(color_layout=\"RGB\", scale=1/127.0, bias=[-1,-1,-1])\n",
        "image_input = ct.ImageType(color_layout=\"RGB\", scale=1/255.0, bias=[0,0,0])\n",
        "# classifier_config = ct.ClassifierConfig(labels)\n",
        "\n",
        "# Set input as ImageType so CoreML can automatically resize it using Vision framework\n",
        "coreml_model = ct.convert(model, inputs=[image_input])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNzcTTYMCUkR"
      },
      "source": [
        "## Get Model input specs\n",
        "There should be a 1/255.0 scaler, The model input is between 0 to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--uqy4qVu_M_"
      },
      "source": [
        "# # Define Spec Function\n",
        "from coremltools.models.neural_network.builder import _get_nn_spec as get_nn\n",
        "\n",
        "## Get Spec and check preprocessing\n",
        "spec = coreml_model.get_spec()\n",
        "nn = get_nn(spec)\n",
        "print(nn.preprocessing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-s9ZjAK1oY4"
      },
      "source": [
        "# Save CoreML Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWMNOVeeCKM7"
      },
      "source": [
        "## Create model folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs7aWbBeCIs6"
      },
      "source": [
        "model_name = MODEL_FILENAME.split(\"/\")[-1]\n",
        "folder_name = GDRIVE_FOLDER + \"/CoreML\"\n",
        "!mkdir -p {folder_name}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S3RJDjmCM3_"
      },
      "source": [
        "## Save model to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J-llQvsd_7M"
      },
      "source": [
        "coreml_file_path = \"{0}/{1}.mlmodel\".format(folder_name, model_name)\n",
        "coreml_model.save(coreml_file_path)\n",
        "print(\"Core ML model {} saved in {}\".format(model_name, folder_name))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}